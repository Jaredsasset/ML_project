{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('./data/musinsa_top_link_li.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "data = data[0]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review(driver, p_name, link, cnt):\n",
    "    global on_page\n",
    "    time.sleep(0.1)\n",
    "    \n",
    "    # 출력 용도\n",
    "    try:\n",
    "        on_page = driver.find_element(By.CSS_SELECTOR, '#reviewListFragment > div.nslist_bottom > div.pagination.textRight > div > a.paging-btn.btn.active').text\n",
    "    except:\n",
    "        # on_page = driver.find_element(By.CSS_SELECTOR, '#reviewListFragment > div > div.nslist_bottom > div.pagination.textRight > div > a.paging-btn.btn.active').text\n",
    "        pass\n",
    "\n",
    "    # 한 페이지의 전체 리뷰 리스트(최대 10개씩)\n",
    "    req = driver.page_source\n",
    "    soup = BeautifulSoup(req, 'html.parser')\n",
    "    review10 = soup.find_all(class_='review-list')\n",
    "\n",
    "    for i in range(len(review10)):\n",
    "        if cnt==10:\n",
    "                break\n",
    "        \n",
    "        try:\n",
    "            # 사이즈 - 보통이에요\n",
    "            if review10[i].find(class_='review-evaluation__list').find_all('li')[0].span.text == '보통이에요':\n",
    "                size_rev = '보통'\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            # 성별, 키, 몸무게, 사이즈\n",
    "            body_info = review10[i].find(class_='review-profile__body_information').text.split(' · ')\n",
    "            sex = body_info[0]\n",
    "            height = body_info[1].replace('cm', '')\n",
    "            weight = body_info[2].replace('kg', '')\n",
    "            size = review10[i].find(class_='review-goods-information__option').text.strip() \n",
    "\n",
    "            # print(p_name, size, size_rev, sex, height, weight, link)\n",
    "\n",
    "            review_list.append({\n",
    "                '제품명':p_name,\n",
    "                '사이즈':size,\n",
    "                '리뷰':size_rev,\n",
    "                '성별':sex,\n",
    "                '키':height,\n",
    "                '몸무게':weight,\n",
    "                '링크':link\n",
    "            })\n",
    "            cnt += 1\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return on_page, cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 코드\n",
    "\n",
    "# 드라이버 옵션 생성 및 창 숨기기 옵션 추가\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"headless\")\n",
    "\n",
    "review_list = []\n",
    "\n",
    "# 0~1799(1800개)번째 리뷰 추출\n",
    "for link in tqdm(data[486:1800]):\n",
    "    try:\n",
    "        # driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n",
    "        driver = webdriver.Chrome('../chromedriver_win32/chromedriver.exe', options=options)\n",
    "        driver.get(link)\n",
    "        \n",
    "        # 추천 순 클릭\n",
    "        driver.find_element(By.ID, 'reviewSelectSort').send_keys('추천 순')\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        # 페이지 크롤링\n",
    "        req = driver.page_source\n",
    "        soup = BeautifulSoup(req, 'html.parser')\n",
    "\n",
    "        # 제품명\n",
    "        p_name = soup.find(class_='product_title').em.text.strip()\n",
    "\n",
    "        # 리뷰 페이지 전체 수\n",
    "        try:\n",
    "            total_page = soup.find('div','box_page_msg').text.strip().split(' 페이지')[0]\n",
    "            # print(total_page)\n",
    "        except:\n",
    "            driver.close()\n",
    "            continue\n",
    "        \n",
    "        # 제품 당 10개 리뷰 가져오기 위한 카운트\n",
    "        cnt = 0\n",
    "\n",
    "        # 첫 페이지 크롤링\n",
    "        on_page, cnt = get_review(driver, p_name, link, cnt)\n",
    "\n",
    "        # 페이지 넘기기\n",
    "        flag=True\n",
    "        while flag:\n",
    "            for i in range(4, 9):\n",
    "                \n",
    "                if (cnt== 10) | (on_page == total_page):\n",
    "                    flag=False\n",
    "                    break\n",
    "\n",
    "                page_ = f'#reviewListFragment > div.nslist_bottom > div.pagination.textRight > div > a:nth-child({i})'\n",
    "                \n",
    "                try:\n",
    "                    driver.find_element(By.CSS_SELECTOR, page_).send_keys(Keys.ENTER)\n",
    "                except:\n",
    "                    page_ = f'#reviewListFragment > div:nth-child(3) > div.nslist_bottom > div.pagination.textRight > div > a:nth-child({i})'\n",
    "                    driver.find_element(By.CSS_SELECTOR, page_).send_keys(Keys.ENTER)\n",
    "                    \n",
    "                \n",
    "                on_page, cnt = get_review(driver, p_name, link, cnt)\n",
    "\n",
    "                \n",
    "\n",
    "        driver.close()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(review_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/top_review_1_1800.csv', encoding='euc-kr')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
